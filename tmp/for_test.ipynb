{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "author_dict = pickle.load(open('data/citationv1_author.pkl','rb'))\n",
    "node_dict = pickle.load(open('data/citationv1.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Automated Deduction in Geometry: 5th International Workshop, ADG 2004, Gainesville, FL, USA, September 16-18, 2004, Revised Papers (Lecture Notes in Computer ... / Lecture Notes in Artificial Intelligence)',\n",
       " 'authers': ['Hoon Hong', 'Dongming Wang'],\n",
       " 'year': 2006,\n",
       " 'venue': '',\n",
       " 'index': 0,\n",
       " 'references': [],\n",
       " 'abstract': '',\n",
       " 'cited': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_graph(index):\n",
    "    g = nx.DiGraph()\n",
    "    root_name = node_dict[index]['title']\n",
    "    g.add_node(index,label = root_name,modularity_class = 'self')\n",
    "    for nd in node_dict[index]['references']:\n",
    "        g.add_node(nd,label = node_dict[nd]['title'],modularity_class = 'references')\n",
    "        g.add_edge(nd,index)\n",
    "    for nd in node_dict[index]['cited']:\n",
    "        g.add_node(nd,label = node_dict[nd]['title'],modularity_class = 'cited')\n",
    "        g.add_edge(index,nd)\n",
    "    for aut in node_dict[index]['authers']:\n",
    "        for nd in author_dict[aut]:\n",
    "            if nd not in g.nodes:\n",
    "                g.add_node(nd,label = node_dict[nd]['title'],modularity_class = 'co-author')\n",
    "                g.add_edge(index,nd)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen_graph(436405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'Information geometry of U-Boost and Bregman divergence', 'modularity_class': 'self'}\n",
      "{'label': 'A decision-theoretic generalization of on-line learning and an application to boosting', 'modularity_class': 'references'}\n",
      "{'label': 'Boosting as entropy projection', 'modularity_class': 'references'}\n",
      "{'label': 'Information geometry of the EM and em algorithms for neural networks', 'modularity_class': 'references'}\n",
      "{'label': 'Neural Networks for Pattern Recognition', 'modularity_class': 'references'}\n",
      "{'label': 'Logistic Regression, AdaBoost and Bregman Distances', 'modularity_class': 'references'}\n",
      "{'label': 'MadaBoost: A Modification of AdaBoost', 'modularity_class': 'references'}\n",
      "{'label': 'Boosting a weak learning algorithm by majority', 'modularity_class': 'references'}\n",
      "{'label': 'The Strength of Weak Learnability', 'modularity_class': 'references'}\n",
      "{'label': 'The nature of statistical learning theory', 'modularity_class': 'references'}\n",
      "{'label': 'Interpreting Kullback-Leibler divergence with the Neyman-Pearson lemma', 'modularity_class': 'cited'}\n",
      "{'label': 'Robust boosting algorithm against mislabeling in multiclass problems', 'modularity_class': 'cited'}\n",
      "{'label': 'Multiclass Boosting Algorithms for Shrinkage Estimators of Class Probability', 'modularity_class': 'cited'}\n",
      "{'label': 'Tutorial series on brain-inspired computing: part 6: geometrical structure of boosting algorithm', 'modularity_class': 'cited'}\n",
      "{'label': 'Robust parameter estimation with a small bias against heavy contamination', 'modularity_class': 'cited'}\n",
      "{'label': 'Robust Loss Functions for Boosting', 'modularity_class': 'cited'}\n",
      "{'label': 'An Information Theoretic Perspective of the Sparse Coding', 'modularity_class': 'co-author'}\n",
      "{'label': 'Support vector machines with different norms: motivation, formulations and results', 'modularity_class': 'co-author'}\n",
      "{'label': 'A statistical study of on-line learning', 'modularity_class': 'co-author'}\n",
      "{'label': 'On-line learning in switching and drifting environments with application to blind source separation', 'modularity_class': 'co-author'}\n",
      "{'label': 'Learning Curves, Model Selection and Complexity of Neural Networks', 'modularity_class': 'co-author'}\n",
      "{'label': 'Calibration of Radially Symmetric Distortion by Fitting Principal Component', 'modularity_class': 'co-author'}\n",
      "{'label': 'Bayesian Collaborative Predictors for General User Modeling Tasks', 'modularity_class': 'co-author'}\n",
      "{'label': 'GroupAdaBoost for Selecting Important Genes', 'modularity_class': 'co-author'}\n",
      "{'label': 'Inlier-Based Outlier Detection via Direct Density Ratio Estimation', 'modularity_class': 'co-author'}\n",
      "{'label': 'Nonparametric conditional density estimation using piecewise-linear solution path of kernel quantile regression', 'modularity_class': 'co-author'}\n",
      "{'label': 'Pool-based active learning with optimal sampling distribution and its information geometrical interpretation', 'modularity_class': 'co-author'}\n",
      "{'label': 'A New Sequential Algorithm for Regression Problems by Using Mixture Distribution', 'modularity_class': 'co-author'}\n",
      "{'label': 'Image classification based on Markov random field models with Jeffreys divergence', 'modularity_class': 'co-author'}\n",
      "{'label': 'Robust Principal Component Analysis with Adaptive Selection for Tuning Parameters', 'modularity_class': 'co-author'}\n"
     ]
    }
   ],
   "source": [
    "for node in g.nodes:\n",
    "    print(g.nodes[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '1'\n",
    "str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\"\n"
     ]
    }
   ],
   "source": [
    "a = '\"1\"'\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
